# -*- coding: utf-8 -*-
"""imvigor.ipynb

Automatically generated by Colaboratory.

Recommend to run in .ipynb type

## **Load data**
"""

from google.colab import drive
drive.mount('/content/gdrive')

# Commented out IPython magic to ensure Python compatibility.
# %pwd
# %cd 'gdrive/My Drive/bladder cancer'
# %ls

import pandas as pd
import numpy as np

# Commented out IPython magic to ensure Python compatibility.
# xlsx = pd.read_excel('./IMvigor210.xlsx', sheet_name = 'clin' )
# # xlsx.to_csv('./imvigor210_clin.csv',index=False)
# print(xlsx.columns)
# %ls

data = pd.read_csv("IMvigor210_clin.csv")
print(data.columns)

len(data)

print(data.mean()['Neoantigen burden per MB'])

"""## **Data Preprocessing**"""

## match non-digit labels to digits

data['Best Confirmed Overall Response'] = data['Best Confirmed Overall Response'].map({'CR':0, 'PR':1, 'SD':2, 'PD':3})
data['Enrollment IC'] = data['Enrollment IC'].map({'IC0':0, 'IC1':1, 'IC2':2})
# NA = -1
data['Immune phenotype'] = data['Immune phenotype'].map({'desert':0, 'inflamed':1, 'excluded':2})
data['Immune phenotype'] = data['Immune phenotype'].fillna(-1)
data['Sex'] = data['Sex'].map({'M':0, 'F':1})
# NA = -1, rm 'NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER' since the number of it is 1
data['Race'] = data['Race'].map({'BLACK OF AFRICAN AMERICAN':0, 'ASIAN':1, 'WHITE':2,  'OTHER':4})
data['Race'] = data['Race'].fillna(-1)
data['Intravesical BCG administered'] = data['Intravesical BCG administered'].map({'N':0, 'Y':1})
data['Tobacco Use History'] = data['Tobacco Use History'].map({'NEVER':0, 'PREVIOUS':1, 'CURRENT':2})

# # replace NA to the mean of N, Y
# data['Met Disease Status'] = data['Met Disease Status'].map({'Liver':0, 'Visceral':1, 'LN Only':2, 'NA': -1})
data['Sample age'] = data['Sample age'].map({'(less than) 1 year':0, '1-2 years':1, 'more than 2 years':2})
data['Received platinum'] = data['Received platinum'].map({'N':0, 'Y':1})

# replace NA to the mean of N, Y
#data['Sample collected pre-platinum'] = data['Sample collected pre-platinum'].map({'N':0, 'Y':1, 'NA': 0.5})
data['Lund'] = data['Lund'].map({'MS1a':0, 'MS1b':1, 'MS2a1':2,'MS2a2':3, 'MS2b1':4, 'MS2b2.1':5, 'MS2b2.2':6})
data['Lund2'] = data['Lund2'].map({'UroA':0, 'UroB':1, 'Genomically unstable':3, 'Infiltrated':4, 'Basal/SCC-like':5})
data['TCGA Subtype'] = data['TCGA Subtype'].map({'I':0, 'II':1, 'III':2, 'IV':3})     

# replace NA to the mean of column 
data['Neoantigen burden per MB'] = data['Neoantigen burden per MB'].fillna(data.mean()['Neoantigen burden per MB'])
# replace NA to the mean of column 
data['FMOne mutation burden per MB'] = data['FMOne mutation burden per MB'].fillna(data.mean()['FMOne mutation burden per MB'])


features = ['Enrollment IC', 'Immune phenotype','FMOne mutation burden per MB', 'Sex', 'Race', 
            'Intravesical BCG administered', 'Baseline ECOG Score', 'Tobacco Use History', 'Sample age', 'Received platinum', 
            'Neoantigen burden per MB', 'sizeFactor', 'os', 'censOS', 'Lund', 'Lund2', 'TCGA Subtype' ]

data = data[features]

len(data.columns)

target_column = 'TCGA Subtype'

## split train and test data

from sklearn.model_selection import StratifiedShuffleSplit
split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=1004)

for train_idx, test_idx in split.split(data, data[target_column]):
    train = data.loc[train_idx]
    test = data.loc[test_idx]

print(len(train), len(test))

print(train.groupby(target_column).size())
print(test.groupby(target_column).size())

## encode y to one-hot vector

from sklearn.preprocessing import LabelEncoder
encoder =  LabelEncoder()

y_train = train[target_column]
Y = encoder.fit_transform(y_train)
y_train = pd.get_dummies(Y).values

y_test = test[target_column]
Y = encoder.fit_transform(y_test)
y_test = pd.get_dummies(Y).values

x_train = train.drop([target_column], axis = 1)
x_test = test.drop([target_column], axis = 1)

features.remove(target_column)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import seaborn as sns

sns.set(style="ticks", color_codes=True)
g = sns.pairplot(train, hue=target_column, palette="husl")

g.savefig(target_column+".png")

# data.columns[data.isnull().any()]
# print(data['Immune phenotype'])

"""## **K nearest neighbor**"""

# KNN
from sklearn.neighbors import KNeighborsClassifier

for i in range(1, 16):
  knn = KNeighborsClassifier(n_neighbors=i)

  knn.fit(x_train, y_train)

  KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
            metric_params=None, n_jobs=1, n_neighbors=1, p=2,
            weights='uniform')

  y_pred = knn.predict(x_test)
  print(accuracy_score(y_test, y_pred))

"""# **Neural Networks**"""

x_train.shape, x_test.shape, y_train.shape, y_test.shape

len(features)

y_train.shape[1]

from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.optimizers import Adam
from keras import regularizers


model = Sequential()

model.add(Dense(64, input_shape=(len(features),), activation='relu'))
model.add(Dropout(0.1))
model.add(Dense(64, activation='relu', kernel_regularizer='l1'))
model.add(Dense(y_train.shape[1], activation='softmax'))

opt = Adam(learning_rate=0.001)
model.compile(loss='categorical_crossentropy', 
              optimizer=opt, 
              metrics=['accuracy'])

model.summary()

hist = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=300)

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

plt.figure(figsize=(12,8))
plt.plot(hist.history['loss'])
plt.plot(hist.history['val_loss'])
plt.plot(hist.history['accuracy'])
plt.plot(hist.history['val_accuracy'])
plt.legend(['loss','val_loss', 'acc','val_acc'])
plt.grid()
plt.show()

loss, accuracy = model.evaluate(x_test, y_test)
print("Accuracy = {:.2f}".format(accuracy))



"""# **Decision Tree**"""

# Decision Tree
from sklearn.tree import DecisionTreeClassifier

tree_clf = DecisionTreeClassifier(max_depth=16) 
tree_clf.fit(x_train, y_train)


# gini = impurity of each node
# gini == 0 means the node is completely pure and contains data of the same class.
DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=16, 
                       max_features=None, max_leaf_nodes=None, 
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0,
                       presort=False, random_state=1004, splitter='best')

pred = tree_clf.predict(x_test)
print("accuracy of decision tree:", accuracy_score(y_test, pred))

# accuracy w/o library
c = 0
for i in range (pred.shape[0]):
  if np.all(pred[i, :] == y_test[i, :]):
    c = c+1
print(c/70)

from sklearn.tree import export_graphviz
import graphviz
import os

def image_path(fig_id):
  return os.path.join('./', fig_id)

export_graphviz(
    tree_clf,
    out_file = image_path('tree_' + target_column + '.dot'),
    feature_names = features,
    class_names = target_column,
    rounded = True,
    filled = True
)

with open('tree_' + target_column + '.dot') as f:
  dot_graph = f.read()

dot = graphviz.Source(dot_graph)
dot.format = 'png'
dot.render(filename = 'tree_'+target_column, directory = './', cleanup = True)
dot

