# -*- coding: utf-8 -*-
"""classify by biomarkers_cross validation

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aS10lxl6U7i8iCBNB4xtivbs7D9RQKln

## **Load data**
"""

from google.colab import drive
drive.mount('/content/gdrive')

# Commented out IPython magic to ensure Python compatibility.
# %pwd
# %cd 'gdrive/My Drive/bladder cancer'
# %ls

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Commented out IPython magic to ensure Python compatibility.
# xlsx = pd.read_excel('./IMvigor210.xlsx', sheet_name = 'TMM norm' )
# xlsx.to_csv('./tmm.csv',index=False)
# print(xlsx.columns)
# %ls

data = pd.read_csv("IMvigor210_clin.csv")
print(data.columns)
print(len(data))

marker = pd.read_csv("tmm.csv")
ori_marker = marker

marker.columns

"""## **Data Preprocessing**"""

marker = marker.rename(columns = {'Symbol':'SampleID'}) 
marker = marker.drop(['Entrez Gene ID'], axis = 1).T
marker.columns = marker.iloc[0]
marker = marker.drop(marker.index[0])

print(marker.head())

len(marker), len(marker.columns)

target_column = 'Immune phenotype'

## match non-digit labels to digits

# data['Best Confirmed Overall Response'] = data['Best Confirmed Overall Response'].map({'CR':0, 'PR':1, 'SD':2, 'PD':3, 'NE':4})
# data['Enrollment IC'] = data['Enrollment IC'].map({'IC0':0, 'IC1':1, 'IC2':2})

# NA = -1 -> nan 빼고 해보기
data['Immune phenotype'] = data['Immune phenotype'].map({'desert':0, 'inflamed':1, 'excluded':2})

# data['Sex'] = data['Sex'].map({'M':0, 'F':1})
# # NA = -1, rm 'NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER' since the number of it is 1
# data['Race'] = data['Race'].map({'BLACK OF AFRICAN AMERICAN':0, 'ASIAN':1, 'WHITE':2,  'OTHER':4})
# data['Race'] = data['Race'].fillna(-1)
# data['Intravesical BCG administered'] = data['Intravesical BCG administered'].map({'N':0, 'Y':1})
# data['Tobacco Use History'] = data['Tobacco Use History'].map({'NEVER':0, 'PREVIOUS':1, 'CURRENT':2})

# # # replace NA to the mean of N, Y
# # data['Met Disease Status'] = data['Met Disease Status'].map({'Liver':0, 'Visceral':1, 'LN Only':2, 'NA': -1})
# data['Sample age'] = data['Sample age'].map({'(less than) 1 year':0, '1-2 years':1, 'more than 2 years':2})
# data['Received platinum'] = data['Received platinum'].map({'N':0, 'Y':1})

# # replace NA to the mean of N, Y
# #data['Sample collected pre-platinum'] = data['Sample collected pre-platinum'].map({'N':0, 'Y':1, 'NA': 0.5})
# data['Lund'] = data['Lund'].map({'MS1a':0, 'MS1b':1, 'MS2a1':2,'MS2a2':3, 'MS2b1':4, 'MS2b2.1':5, 'MS2b2.2':6})
# data['Lund2'] = data['Lund2'].map({'UroA':0, 'UroB':1, 'Genomically unstable':3, 'Infiltrated':4, 'Basal/SCC-like':5})
# data['TCGA Subtype'] = data['TCGA Subtype'].map({'I':0, 'II':1, 'III':2, 'IV':3})     

# # replace NA to the mean of column 
# data['Neoantigen burden per MB'] = data['Neoantigen burden per MB'].fillna(data.mean()['Neoantigen burden per MB'])
# # replace NA to the mean of column 
# data['FMOne mutation burden per MB'] = data['FMOne mutation burden per MB'].fillna(data.mean()['FMOne mutation burden per MB'])

  

print(data[target_column])

if target_column in marker.columns:
  marker = marker.drop(target_column, axis = 1)

data.index = data['SampleID']
marker.index.equals(data.index)

marker = marker.join(data[target_column])
marker = marker.reset_index()
marker = marker.rename(columns = {'index':'SampleID'}) 
marker.head()

marker.index

marker = marker.dropna(axis=0)
marker.shape

marker.reset_index(inplace=True, drop=True)
marker.index

######17694 check
marker.shape

# split train and test data
# 5-fold cross validation

train_list = []
test_list = []

from sklearn.model_selection import StratifiedKFold
fold = StratifiedKFold(n_splits=5, shuffle=False, random_state=1004)

for train_idx, test_idx in fold.split(marker, marker[target_column]):
    # print("TRAIN:", train_idx, "\nTEST:", test_idx)
    train_list.append(marker.loc[train_idx])
    test_list.append(marker.loc[test_idx])

print(len(train_list), len(test_list))

# groupby 1 df

print(train_list[0].groupby(target_column).size())
print(test_list[0].groupby(target_column).size())

# check the average number of total 5 training data per class
total_train = pd.concat([train_list[0], train_list[1], train_list[2], train_list[3], train_list[4]], axis=0, ignore_index=True)
print(total_train.groupby(target_column).size())
print('\n', total_train.groupby(target_column).size()/5)

# check the average number of total 5 test data per class
total_test = pd.concat([test_list[0], test_list[1], test_list[2], test_list[3], test_list[4]], axis=0, ignore_index=True)
print(total_test.groupby(target_column).size())
print('\n', total_test.groupby(target_column).size()/5)

from sklearn.preprocessing import LabelEncoder
encoder =  LabelEncoder()

x_train_list, x_test_list, y_train_list, y_test_list = [], [], [], []
decoded_y_train_list, decoded_y_test_list = [], []

for (train, test) in zip(train_list, test_list): 
  decoded_y_train = train[target_column]
  Y = encoder.fit_transform(decoded_y_train)
  y_train = pd.get_dummies(Y).values

  decoded_y_test = test[target_column]
  Y = encoder.fit_transform(decoded_y_test)
  y_test = pd.get_dummies(Y).values

  x_train = train.drop([target_column], axis = 1)
  x_test = test.drop([target_column], axis = 1)

  features = marker.columns.tolist()
  features.remove(target_column)
  features.remove('SampleID')

  x_train.set_index(x_train['SampleID'], inplace=True, drop=True)
  x_test.set_index(x_test['SampleID'], inplace=True, drop=True)

  x_train.drop(['SampleID'], axis=1, inplace=True)
  x_test.drop(['SampleID'], axis=1, inplace=True)
  x_train.reset_index(drop=True, inplace=True)
  x_test.reset_index(drop=True, inplace=True)

  x_test = np.asarray(x_test).astype(np.float32)
  x_train = np.asarray(x_train).astype(np.float32)

  x_train_list.append(x_train)
  x_test_list.append(x_test)
  y_train_list.append(y_train)
  y_test_list.append(y_test)
  decoded_y_train_list.append(decoded_y_train)
  decoded_y_test_list.append(decoded_y_test)

from keras import backend as K
import tensorflow as tf

def result(one_pred, y_test):
  acc, rec, pre = [], [], []
  
  for target_class in range(y_test.shape[1]):
    """RECALL"""

    tp = K.sum(one_pred[:, target_class] * y_test[:, target_class])  #dtype=float32
    tpfn = tf.cast(K.sum(y_test[:, target_class]), tf.float32)  #uint8 to float32

    # Recall =  (True Positive) / (True Positive + False Negative)
    recall = tp / (tpfn + K.epsilon())

    """PRECISION"""

    tpfp = tf.cast(K.sum(one_pred[:, target_class]), tf.float32)

    # Precision = (True Positive) / (True Positive + False Positive)
    precision = tp / (tpfp + K.epsilon())

    """Accuracy"""
    tn = np.sum((one_pred[:, target_class]==0) * (y_test[:, target_class]==0).T)

    accuracy = (tp + tn)/(tpfn + tpfp - tp + tn)

    acc.append(accuracy)
    rec.append(recall)
    pre.append(precision)

    print("\nclass: ", target_class)
    print("tp: ", tp)
    print("tp+fn: ", tpfn)
    print("tp+fp: ", tpfp)

    tf.print("Accuracy = {:.3f}".format(accuracy))
    tf.print("Recall = {:.3f}".format(recall))
    tf.print("Precision = {:.3f} ".format(precision))

  return acc, rec, pre

"""# **Neural Networks**"""

one_pred_list = []

# Commented out IPython magic to ensure Python compatibility.
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.optimizers import Adam
from keras import regularizers
from keras.callbacks import EarlyStopping
# %matplotlib inline

# EarlyStopping = EarlyStopping(monitor='val_loss', patience=20)

for (x_train, x_test, y_train, y_test) in zip(x_train_list, x_test_list, y_train_list, y_test_list):

  model = Sequential()

  model.add(Dense(y_train.shape[1], input_shape=(len(features),), activation='softmax'))

  opt = Adam(learning_rate=0.00001)
  model.compile(loss='categorical_crossentropy', 
                optimizer=opt, 
                metrics=['accuracy']) 


  # model.summary()

  hist = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=500, verbose=0)

  plt.figure(figsize=(12,8))
  plt.plot(hist.history['loss'])
  plt.plot(hist.history['val_loss'])
  plt.plot(hist.history['accuracy'])
  plt.plot(hist.history['val_accuracy'])
  plt.legend(['loss','val_loss', 'acc','val_acc'])
  plt.grid()
  plt.show()

  prediction = model.predict(x_test, verbose=1)
  one_pred = np.zeros_like(prediction)
  # one hot encoding of prediction
  one_pred[np.arange(len(prediction)), prediction.argmax(1)] = 1
  one_pred_list.append(one_pred)

# import tensorflow as tf
# tf.test.gpu_device_name()

# for one_pred, y_test in zip(one_pred_list, y_test_list):
#   print(one_pred.shape)
#   print(y_test.shape)

acc_list, rec_list, pre_list = [], [], []

for one_pred, y_test in zip(one_pred_list, y_test_list):
  acc, rec, pre = result(one_pred, y_test)
  acc_list.append(acc)
  rec_list.append(rec)
  pre_list.append(pre)

# number of class
for i in range(y_test_list[0].shape[1]):
  acc_mean, rec_mean, pre_mean = 0, 0, 0
  
  # k-fold
  for j in range(len(acc_list)):  
    acc_mean += acc_list[j][i]
    rec_mean += rec_list[j][i]
    pre_mean += pre_list[j][i]
  
  acc_mean /= len(acc_list)
  rec_mean /= len(rec_list)
  pre_mean /= len(pre_list)

  print("\nclass: ", i)
  # mean score of k-folds
  tf.print("Accuracy = {:.3f}".format(acc_mean))
  tf.print("Recall = {:.3f}".format(rec_mean))
  tf.print("Precision = {:.3f} ".format(pre_mean))

len(acc_list)

"""# **SVM**"""

acc_list, rec_list, pre_list = [], [], []

# Support Vector Classifier
# one vs rest

from sklearn.svm import SVC
from sklearn.multiclass import OneVsRestClassifier

for x_train, decoded_y_train, x_test, y_test in zip(x_train_list, decoded_y_train_list, x_test_list, y_test_list):
  svm = OneVsRestClassifier(SVC()).fit(x_train, decoded_y_train)
  y_pred_svc = svm.predict(x_test)

  # print(y_pred_svc)

  # encode y_pred_svc to one-hot vector 
  Y = encoder.fit_transform(y_pred_svc)
  y_pred_svc = pd.get_dummies(Y).values.astype(np.float32)

  acc, rec, pre = result(y_pred_svc, y_test)
  acc_list.append(acc)
  rec_list.append(rec)
  pre_list.append(pre)

# number of class
for i in range(y_test_list[0].shape[1]):
  acc_mean, rec_mean, pre_mean = 0, 0, 0
  
  # k-fold
  for j in range(len(acc_list)):  
    acc_mean += acc_list[j][i]
    rec_mean += rec_list[j][i]
    pre_mean += pre_list[j][i]
  
  acc_mean /= len(acc_list)
  rec_mean /= len(rec_list)
  pre_mean /= len(pre_list)

  print("\nclass: ", i)
  # mean score of k-folds
  tf.print("Accuracy = {:.3f}".format(acc_mean))
  tf.print("Recall = {:.3f}".format(rec_mean))
  tf.print("Precision = {:.3f} ".format(pre_mean))

# output개수가 0인 class가 있을 때 add [0]*y_pred_svc.shape[0]

# new_column = [0] * y_pred_svc.shape[0]
# y_pred_svc = np.insert(y_pred_svc, 2, new_column, axis=1)
# y_pred_svc

